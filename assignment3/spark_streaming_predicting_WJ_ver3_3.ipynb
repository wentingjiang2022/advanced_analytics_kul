{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.171:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.171:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1aba5b36320>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40129, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(\"reviews.csv\", sep='\\t')\n",
    "df = df[['review_id', 'app_id', 'review_text', 'label']]\n",
    "df.to_csv('reviews.csv', sep='\\t', index=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>8109</td>\n",
       "      <td>8109</td>\n",
       "      <td>8107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>32019</td>\n",
       "      <td>32019</td>\n",
       "      <td>31966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_id  app_id  review_text\n",
       "label                                \n",
       "0.0         8109    8109         8107\n",
       "1.0        32019   32019        31966"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7979216507177034"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer, HashingTF\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "file_location=\"reviews.csv\"\n",
    "#text_df = spark.read.text(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"assignment 3\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.cores\", \"2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         review_text|label|\n",
      "+--------------------+-----+\n",
      "|i can confirm tha...|  1.0|\n",
      "|Really good game,...|  1.0|\n",
      "|Its not finished ...|  1.0|\n",
      "|Hey. It's really ...|  1.0|\n",
      "|          Fun so far|  1.0|\n",
      "|I'd rather play W...|  0.0|\n",
      "|I have been playi...|  1.0|\n",
      "|Nice game! Loads ...|  1.0|\n",
      "|All hail NA serve...|  1.0|\n",
      "|enjoying it so fa...|  1.0|\n",
      "|This game came as...|  1.0|\n",
      "|         Great fun  |  1.0|\n",
      "|Fantastic consept...|  1.0|\n",
      "|You know the game...|  1.0|\n",
      "|EDIT: My issues h...|  1.0|\n",
      "|AMAZIIIIIIIIIIING...|  1.0|\n",
      "|In its current st...|  0.0|\n",
      "|Играю в Калибр го...|  1.0|\n",
      "|Secret Word: Prou...|  1.0|\n",
      "|Fated Word: Death...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#text_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\", \"true\").csv(file_location)\n",
    "\n",
    "# read csv\n",
    "\n",
    "text_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .csv(file_location)\n",
    "\n",
    "text_df = text_df.select(col('review_text'), col('label'))\n",
    "text_df = text_df.dropna()\n",
    "text_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: (38890, 2)\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows and columns in the DataFrame\n",
    "num_rows = text_df.count()\n",
    "num_cols = len(text_df.columns)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(\"Shape of the DataFrame: (%d, %d)\" % (num_rows, num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "text_df = text_df.dropDuplicates()\n",
    "# Remove rows with missing values\n",
    "text_df = text_df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               label|\n",
      "+--------------------+\n",
      "|                 1.0|\n",
      "|                 0.0|\n",
      "|It's been at leas...|\n",
      "|[td]✔️ Exciting p...|\n",
      "|- I literally onl...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_df.select(\"label\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering:  36913\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with unexpected labels\n",
    "text_df = text_df.filter((col(\"label\") == 1.0) | (col(\"label\") == 0.0))\n",
    "print(\"Number of rows after filtering: \", text_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 labelled:  11926\n",
      "0 labelled:  3088\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = text_df.limit(15014).randomSplit([0.8, 0.2], seed=7)\n",
    "print(\"1 labelled: \", train_data.filter(col(\"label\") == 1.0).count()+test_data.filter(col(\"label\") == 1.0).count())\n",
    "print(\"0 labelled: \", train_data.filter(col(\"label\") == 0.0).count()+test_data.filter(col(\"label\") == 0.0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "tokenizer = Tokenizer(inputCol=\"review_text\", outputCol=\"words\")\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\", locale=\"en_US\")\n",
    "count_vectorizer = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"raw_features\")\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "string_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
    "\n",
    "# create model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define params grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "   .addGrid(count_vectorizer.vocabSize, [1000, 5000]) \\\n",
    "   .addGrid(lr.regParam, [0.01, 0.1]) \\\n",
    "   .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "   .build()\n",
    "\n",
    "# define the evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, count_vectorizer, idf, string_indexer, lr])\n",
    "\n",
    "# define the cross-validator\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# fit pipeline to the training data\n",
    "cv_model = cv.fit(train_data)\n",
    "\n",
    "# make predictions on the test data\n",
    "predictions = cv_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8657\n",
      "F1 score: 0.8573\n",
      "Recall: 0.8657\n",
      "Precision: 0.8576\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "# Calculate recall\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Calculate precision\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"F1 score: {:.4f}\".format(f1_score))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\spark-3.3.2-bin-hadoop2\\python\\pyspark\\sql\\context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[2321.  118.]\n",
      " [ 296.  348.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# Convert the predictions and labels to an RDD\n",
    "predictionAndLabels = predictions.select(\"prediction\", \"label_index\").rdd.map(lambda r: (r[0], r[1]))\n",
    "\n",
    "# Instantiate a MulticlassMetrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# Get the confusion matrix as a NumPy array\n",
    "confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the cross-validation process\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# Save the my_model\n",
    "best_model.save(\"my_logistic_regression3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      "Vocab Size:  5000\n",
      "Regularization Parameter:  0.01\n",
      "Elastic Net Parameter:  0.0\n"
     ]
    }
   ],
   "source": [
    "lr_stage = best_model.stages[-1] \n",
    "print(\"Best Parameters: \")\n",
    "print(\"Vocab Size: \", best_model.stages[2].getVocabSize())  # Assuming count_vectorizer is at index 2\n",
    "print(\"Regularization Parameter: \", lr_stage.getRegParam())\n",
    "print(\"Elastic Net Parameter: \", lr_stage.getElasticNetParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "globals()['models_loaded'] = False\n",
    "globals()['my_model'] = None\n",
    "\n",
    "global results\n",
    "results = []\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    df = df.withColumn(\"label\", col(\"label\").cast(\"float\"))\n",
    "    df.show()\n",
    "    \n",
    "#     # Utilize our predict function\n",
    "#     df_withpreds = df.withColumn(\"pred\", predict_udf(\n",
    "#         struct([df[x] for x in df.columns])\n",
    "#     ))\n",
    "#     df_withpreds.show()\n",
    "    \n",
    "    # Normally, you wouldn't use a UDF (User Defined Function) Python function to predict as we did here (you can)\n",
    "    # but an MLlib model you've built and saved with Spark\n",
    "    # In this case, you need to prevent loading your model in every call to \"process\" as follows:\n",
    "    \n",
    "    # Load in the model if not yet loaded:\n",
    "    if not globals()['models_loaded']:\n",
    "        # load in your models here\n",
    "        globals()['my_model'] = PipelineModel.load('my_logistic_regression3')\n",
    "        globals()['models_loaded'] = True\n",
    "        \n",
    "    # And then predict using the loaded model (uncomment below):\n",
    "    \n",
    "    df_result = globals()['my_model'].transform(df)\n",
    "    df_result.select('label', 'review_text', 'prediction','probability', 'label_index').show()\n",
    "    \n",
    "    collected_results = df_result.select('prediction', 'label_index').collect()\n",
    "    results.extend(collected_results)\n",
    "    \n",
    "    # If we have collected 10 results, show the data and clear the results list\n",
    "    display_results(results)\n",
    "\n",
    "\n",
    "def display_results(results):\n",
    "    result_df = spark.createDataFrame(results)\n",
    "    predictionAndLabels = result_df.select(\"prediction\", \"label_index\").rdd.map(lambda r: (r[0], r[1]))\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2023-05-27 10:18:10 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1934780|  0.0|139062886|i have 60000 ping...|\n",
      "|1934780|  1.0|139062252|                  OH|\n",
      "|1304930|  1.0|139064095|I am a very big f...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  0.0|i have 60000 ping...|       1.0|[0.34555838361673...|        1.0|\n",
      "|  1.0|                  OH|       0.0|[0.86250050155218...|        0.0|\n",
      "|  1.0|I am a very big f...|       0.0|[0.99999551381068...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[2. 0.]\n",
      " [0. 1.]]\n",
      "========= 2023-05-27 10:18:20 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1304930|  1.0|139064076|                cool|\n",
      "|1304930|  1.0|139064007|worth more than 3...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|                cool|       0.0|[0.90730064402245...|        0.0|\n",
      "|  1.0|worth more than 3...|       0.0|[0.98323641058595...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[4. 0.]\n",
      " [0. 1.]]\n",
      "========= 2023-05-27 10:18:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1304930|  1.0|139063780|If you're looking...|\n",
      "|1304930|  1.0|139063753|wonderful coop ga...|\n",
      "|1304930|  1.0|139063339| their are  thing...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|If you're looking...|       0.0|[0.94955614124722...|        0.0|\n",
      "|  1.0|wonderful coop ga...|       0.0|[0.99499612232718...|        0.0|\n",
      "|  1.0| their are  thing...|       1.0|[0.02788778940562...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[6. 1.]\n",
      " [0. 1.]]\n",
      "========= 2023-05-27 10:18:40 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1304930|  1.0|139063269|made me cum while...|\n",
      "|1304930|  1.0|139063254|      good gam\\ne\\ne|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|made me cum while...|       0.0|[0.75922825361028...|        0.0|\n",
      "|  1.0|      good gam\\ne\\ne|       0.0|[0.99139167734488...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[8. 1.]\n",
      " [0. 1.]]\n",
      "========= 2023-05-27 10:19:00 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "| 754890|  0.0|139064171|There is no way I...|\n",
      "|2141910|  1.0|139064558|Masterpiece. Than...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  0.0|There is no way I...|       1.0|[0.01422684975848...|        1.0|\n",
      "|  1.0|Masterpiece. Than...|       0.0|[0.99625162128764...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[9. 1.]\n",
      " [0. 2.]]\n",
      "========= 2023-05-27 10:19:10 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2141910|  1.0|139064527|           its magic|\n",
      "|2141910|  1.0|139063844|As a newbie to MT...|\n",
      "|2141910|  1.0|139063020|Obligatory \"don't...|\n",
      "|2141910|  0.0|139062645|not good, can't e...|\n",
      "|1608230|  0.0|139064001|Perdón pero para ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|           its magic|       0.0|[0.89657830972668...|        0.0|\n",
      "|  1.0|As a newbie to MT...|       0.0|[0.98676588225266...|        0.0|\n",
      "|  1.0|Obligatory \"don't...|       0.0|[0.52272099691915...|        0.0|\n",
      "|  0.0|not good, can't e...|       0.0|[0.79051992433116...|        1.0|\n",
      "|  0.0|Perdón pero para ...|       0.0|[0.94755131170920...|        1.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[12.  1.]\n",
      " [ 2.  2.]]\n",
      "========= 2023-05-27 10:19:20 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1608230|  1.0|139063385|Planet of Lana is...|\n",
      "|1972640|  1.0|139062370|Beautiful visuals...|\n",
      "|2425400|  1.0|139062667|This house again?...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|Planet of Lana is...|       0.0|[0.99999642706949...|        0.0|\n",
      "|  1.0|Beautiful visuals...|       0.0|[0.98514408976287...|        0.0|\n",
      "|  1.0|This house again?...|       1.0|[0.24249847565140...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[14.  2.]\n",
      " [ 2.  2.]]\n",
      "========= 2023-05-27 10:19:40 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1276800|  1.0|139064014|It's amazing! Eve...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|It's amazing! Eve...|       0.0|[0.98026749585778...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[15.  2.]\n",
      " [ 2.  2.]]\n",
      "========= 2023-05-27 10:19:50 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2005010|  1.0|139064435|This is a fantast...|\n",
      "|2005010|  0.0|139064391|Game starts out s...|\n",
      "|2005010|  1.0|139064311|This game is legi...|\n",
      "|2005010|  1.0|139064256|No think, purge t...|\n",
      "|2005010|  1.0|139064119|WHILST I LIVE, I ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|This is a fantast...|       0.0|[0.94567965773302...|        0.0|\n",
      "|  0.0|Game starts out s...|       0.0|[0.77276605568926...|        1.0|\n",
      "|  1.0|This game is legi...|       0.0|[0.88687211909779...|        0.0|\n",
      "|  1.0|No think, purge t...|       0.0|[0.96978119372761...|        0.0|\n",
      "|  1.0|WHILST I LIVE, I ...|       0.0|[0.82668118038148...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[19.  2.]\n",
      " [ 3.  2.]]\n",
      "========= 2023-05-27 10:20:00 =========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2005010|  1.0|139063946|MY ARMOUR IS CONT...|\n",
      "|2005010|  1.0|139063940|20 dollah make yo...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|MY ARMOUR IS CONT...|       0.0|[0.85303644236814...|        0.0|\n",
      "|  1.0|20 dollah make yo...|       0.0|[0.86712068851988...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[21.  2.]\n",
      " [ 3.  2.]]\n",
      "========= 2023-05-27 10:20:10 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2005010|  1.0|139063879|Absolutely love t...|\n",
      "|2005010|  1.0|139063716|You can feel the ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|Absolutely love t...|       0.0|[0.98898021711149...|        0.0|\n",
      "|  1.0|You can feel the ...|       0.0|[0.92154784417375...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[23.  2.]\n",
      " [ 3.  2.]]\n",
      "========= 2023-05-27 10:20:20 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2335190|  1.0|139062580|I thoroughly enjo...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|I thoroughly enjo...|       0.0|[0.98813989577769...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[24.  2.]\n",
      " [ 3.  2.]]\n",
      "========= 2023-05-27 10:20:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1709350|  1.0|139064384|Very solid platfo...|\n",
      "|2280390|  1.0|139064799|Very good game. T...|\n",
      "|1611290|  1.0|139063486|Fun, great for a ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|Very solid platfo...|       0.0|[0.98088114270457...|        0.0|\n",
      "|  1.0|Very good game. T...|       0.0|[0.82615578911261...|        0.0|\n",
      "|  1.0|Fun, great for a ...|       0.0|[0.97000367835413...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[27.  2.]\n",
      " [ 3.  2.]]\n",
      "========= 2023-05-27 10:20:40 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1265780|  0.0|139063616|If anybody could ...|\n",
      "|1964040|  1.0|139063599|Wot if interdimen...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  0.0|If anybody could ...|       0.0|[0.91862309102731...|        1.0|\n",
      "|  1.0|Wot if interdimen...|       0.0|[0.85303644236814...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[28.  2.]\n",
      " [ 4.  2.]]\n",
      "========= 2023-05-27 10:20:50 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1964040|  1.0|139063399|A little bit weir...|\n",
      "|1644320|  1.0|139063425|Don't believe the...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|A little bit weir...|       0.0|[0.98547048818205...|        0.0|\n",
      "|  1.0|Don't believe the...|       0.0|[0.96239838018020...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[30.  2.]\n",
      " [ 4.  2.]]\n",
      "========= 2023-05-27 10:21:00 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2103480|  1.0|139064211|Love this game an...|\n",
      "|1938800|  1.0|139064851|Demo was done in ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|Love this game an...|       0.0|[0.98883797285704...|        0.0|\n",
      "|  1.0|Demo was done in ...|       1.0|[0.19456596003861...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[31.  3.]\n",
      " [ 4.  2.]]\n",
      "========= 2023-05-27 10:21:20 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1853410|  1.0|139064640|This is such a be...|\n",
      "|1468810|  1.0|139064826|           Good game|\n",
      "|2422080|  1.0|139063743|An exciting adven...|\n",
      "|2422080|  1.0|139063405|Oh my god, you gu...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|This is such a be...|       0.0|[0.99986357058555...|        0.0|\n",
      "|  1.0|           Good game|       0.0|[0.90805609238786...|        0.0|\n",
      "|  1.0|An exciting adven...|       0.0|[0.99274127441371...|        0.0|\n",
      "|  1.0|Oh my god, you gu...|       0.0|[0.99998969568780...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[35.  3.]\n",
      " [ 4.  2.]]\n",
      "========= 2023-05-27 10:21:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2422080|  1.0|139063083|A good game for f...|\n",
      "|2422080|  1.0|139062962|An epic adventure...|\n",
      "|2298300|  1.0|139063374|Oh boy, oh boy! I...|\n",
      "|1999740|  1.0|139064477|Fine,i try out su...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|A good game for f...|       0.0|[0.97939723532224...|        0.0|\n",
      "|  1.0|An epic adventure...|       0.0|[0.98976835934746...|        0.0|\n",
      "|  1.0|Oh boy, oh boy! I...|       0.0|[0.99337710341616...|        0.0|\n",
      "|  1.0|Fine,i try out su...|       1.0|[0.36305416068275...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[38.  4.]\n",
      " [ 4.  2.]]\n",
      "========= 2023-05-27 10:21:40 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2140510|  0.0|139064409|too different for...|\n",
      "|2140510|  0.0|139064277|I like the game; ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  0.0|too different for...|       0.0|[0.83648180656936...|        1.0|\n",
      "|  0.0|I like the game; ...|       1.0|[0.24522499391271...|        1.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[38.  4.]\n",
      " [ 5.  3.]]\n",
      "========= 2023-05-27 10:22:00 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2419330|  1.0|139063166|Nice game 👍🏽 Fu...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|Nice game 👍🏽 Fu...|       0.0|[0.97680649839410...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[39.  4.]\n",
      " [ 5.  3.]]\n",
      "========= 2023-05-27 10:22:10 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2219690|  1.0|139063806|I would add this ...|\n",
      "| 855740|  0.0|139066060|Piece of garbage....|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|I would add this ...|       0.0|[0.87156251901553...|        0.0|\n",
      "|  0.0|Piece of garbage....|       1.0|[0.11750272310287...|        1.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[40.  4.]\n",
      " [ 5.  4.]]\n",
      "========= 2023-05-27 10:22:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2412700|  1.0|139065755|Just hopped into ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|Just hopped into ...|       0.0|[0.91417981927252...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[41.  4.]\n",
      " [ 5.  4.]]\n",
      "========= 2023-05-27 10:22:50 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|  1.0|139066648|Im doing my part!...|\n",
      "|1268750|  1.0|139066646|Across the federa...|\n",
      "|1268750|  1.0|139066641| EDF! EDF! EDF! EDF!|\n",
      "|1268750|  1.0|139066528|  I'm doing my part!|\n",
      "|1268750|  1.0|139066217|           addictive|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|Im doing my part!...|       0.0|[0.99960688233834...|        0.0|\n",
      "|  1.0|Across the federa...|       0.0|[0.99794787478964...|        0.0|\n",
      "|  1.0| EDF! EDF! EDF! EDF!|       0.0|[0.85303644236814...|        0.0|\n",
      "|  1.0|  I'm doing my part!|       0.0|[0.96734642448639...|        0.0|\n",
      "|  1.0|           addictive|       0.0|[0.95958273340088...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[46.  4.]\n",
      " [ 5.  4.]]\n",
      "========= 2023-05-27 10:23:00 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|  1.0|139066174|   i'm doing my part|\n",
      "|1268750|  1.0|139066014|  I'm doing my part!|\n",
      "|1268750|  1.0|139065793|Just incase you w...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|   i'm doing my part|       0.0|[0.89465900851868...|        0.0|\n",
      "|  1.0|  I'm doing my part!|       0.0|[0.96734642448639...|        0.0|\n",
      "|  1.0|Just incase you w...|       0.0|[0.99926880805179...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[49.  4.]\n",
      " [ 5.  4.]]\n",
      "========= 2023-05-27 10:23:10 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|  1.0|139065668|i may be BIASED b...|\n",
      "|1268750|  1.0|139065612|I'm doing my part...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|i may be BIASED b...|       0.0|[0.98474314650304...|        0.0|\n",
      "|  1.0|I'm doing my part...|       0.0|[0.88669491929451...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[51.  4.]\n",
      " [ 5.  4.]]\n",
      "========= 2023-05-27 10:24:10 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1783280|  1.0|139065992|The glyph system ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|The glyph system ...|       0.0|[0.99924863887030...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[52.  4.]\n",
      " [ 5.  4.]]\n",
      "========= 2023-05-27 10:25:00 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1934780|  1.0|139065064|its an arcadey ta...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|its an arcadey ta...|       0.0|[0.83356002721159...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[53.  4.]\n",
      " [ 5.  4.]]\n",
      "========= 2023-05-27 10:26:20 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2008100|  0.0|139065396|TLDR: This game i...|\n",
      "|2008100|  1.0|139065174|A great game that...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  0.0|TLDR: This game i...|       1.0|[4.65244602896999...|        1.0|\n",
      "|  1.0|A great game that...|       0.0|[0.99859479576201...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[54.  4.]\n",
      " [ 5.  5.]]\n",
      "========= 2023-05-27 10:26:40 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1304930|  1.0|139066607|           Vewy good|\n",
      "|1304930|  1.0|139066491|enjoyable, especi...|\n",
      "|1304930|  1.0|139066310|This game is amaz...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|           Vewy good|       0.0|[0.91017929188750...|        0.0|\n",
      "|  1.0|enjoyable, especi...|       0.0|[0.89148186515036...|        0.0|\n",
      "|  1.0|This game is amaz...|       0.0|[0.92950003037690...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[57.  4.]\n",
      " [ 5.  5.]]\n",
      "========= 2023-05-27 10:26:50 =========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1304930|  1.0|139066058|Fun game, exited ...|\n",
      "|1304930|  1.0|139066053|Awesome game with...|\n",
      "|1304930|  1.0|139066012|                hapy|\n",
      "|1304930|  1.0|139065902|     i shat my pants|\n",
      "|1304930|  1.0|139065861|Very fun with fri...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|Fun game, exited ...|       0.0|[0.96367204201660...|        0.0|\n",
      "|  1.0|Awesome game with...|       0.0|[0.99917718474980...|        0.0|\n",
      "|  1.0|                hapy|       0.0|[0.85303644236814...|        0.0|\n",
      "|  1.0|     i shat my pants|       0.0|[0.90045771430189...|        0.0|\n",
      "|  1.0|Very fun with fri...|       0.0|[0.96259663437834...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[62.  4.]\n",
      " [ 5.  5.]]\n",
      "========= 2023-05-27 10:27:00 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1304930|  1.0|139065596|got chased by a S...|\n",
      "|1304930|  1.0|139065594|Many naked men ch...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|got chased by a S...|       0.0|[0.96996710292808...|        0.0|\n",
      "|  1.0|Many naked men ch...|       0.0|[0.99826158724843...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[64.  4.]\n",
      " [ 5.  5.]]\n",
      "========= 2023-05-27 10:27:20 =========\n",
      "+------+-----+---------+--------------------+\n",
      "|app_id|label|review_id|         review_text|\n",
      "+------+-----+---------+--------------------+\n",
      "|754890|  1.0|139065975|The world of Firm...|\n",
      "+------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  1.0|The world of Firm...|       0.0|[0.99936723557933...|        0.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[65.  4.]\n",
      " [ 5.  5.]]\n",
      "========= 2023-05-27 10:29:50 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1465560|  0.0|139065495|The game is fun b...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|label|         review_text|prediction|         probability|label_index|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "|  0.0|The game is fun b...|       0.0|[0.84346580191333...|        1.0|\n",
      "+-----+--------------------+----------+--------------------+-----------+\n",
      "\n",
      "Confusion matrix:\n",
      "[[65.  4.]\n",
      " [ 6.  5.]]\n"
     ]
    }
   ],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
