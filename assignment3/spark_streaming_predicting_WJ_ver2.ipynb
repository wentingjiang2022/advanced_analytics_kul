{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.171:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.171:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1be77236320>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2088, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(\"reviews.csv\", sep=',')\n",
    "df = df[['review_id', 'app_id', 'review_text', 'label']]\n",
    "df.to_csv('reviews.csv', sep='\\t', index=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_id  app_id  review_text\n",
       "label                                \n",
       "0.0           71      71           71\n",
       "1.0          394     394          394"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8473118279569892"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer, HashingTF\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "file_location=\"reviews.csv\"\n",
    "#text_df = spark.read.text(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"assignment 3\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.cores\", \"2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         review_text|label|\n",
      "+--------------------+-----+\n",
      "|i can confirm tha...|  1.0|\n",
      "|Really good game,...|  1.0|\n",
      "|Its not finished ...|  1.0|\n",
      "|Hey. It's really ...|  1.0|\n",
      "|          Fun so far|  1.0|\n",
      "|I'd rather play W...|  0.0|\n",
      "|I have been playi...|  1.0|\n",
      "|Nice game!\\nLoads...|  1.0|\n",
      "|All hail NA serve...|  1.0|\n",
      "|enjoying it so fa...|  1.0|\n",
      "|This game came as...|  1.0|\n",
      "|        Great fun \\n|  1.0|\n",
      "|Fantastic consept...|  1.0|\n",
      "|You know the game...|  1.0|\n",
      "|EDIT: My issues h...|  1.0|\n",
      "|AMAZIIIIIIIIIIING...|  1.0|\n",
      "|In its current st...|  0.0|\n",
      "|–ò–≥—Ä–∞—é –≤ –ö–∞–ª–∏–±—Ä –≥–æ...|  1.0|\n",
      "|Secret Word: Prou...|  1.0|\n",
      "|Fated Word: Death...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#text_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\", \"true\").csv(file_location)\n",
    "\n",
    "# read csv\n",
    "\n",
    "text_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .csv(file_location)\n",
    "\n",
    "text_df = text_df.select(col('review_text'), col('label'))\n",
    "text_df = text_df.dropna()\n",
    "text_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: (433, 2)\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows and columns in the DataFrame\n",
    "num_rows = text_df.count()\n",
    "num_cols = len(text_df.columns)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(\"Shape of the DataFrame: (%d, %d)\" % (num_rows, num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "text_df = text_df.dropDuplicates()\n",
    "# Remove rows with missing values\n",
    "text_df = text_df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|  0.0|\n",
      "|  1.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_df.select(\"label\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering:  433\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with unexpected labels\n",
    "text_df = text_df.filter((col(\"label\") == 1.0) | (col(\"label\") == 0.0))\n",
    "print(\"Number of rows after filtering: \", text_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         review_text|label|\n",
      "+--------------------+-----+\n",
      "| Similar to Battl...|  1.0|\n",
      "|\"(BTW I have a bi...|  0.0|\n",
      "|\"Could be an inte...|  1.0|\n",
      "|\"Fun action rogue...|  1.0|\n",
      "|\"I buy a few new ...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = text_df.limit(10000).randomSplit([0.8, 0.2], seed=7)\n",
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "tokenizer = Tokenizer(inputCol=\"review_text\", outputCol=\"words\")\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\", locale=\"en_US\")\n",
    "count_vectorizer = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"raw_features\")\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "string_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
    "\n",
    "# create model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define params grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "   .addGrid(count_vectorizer.vocabSize, [1000, 5000]) \\\n",
    "   .addGrid(lr.regParam, [0.01, 0.1]) \\\n",
    "   .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "   .build()\n",
    "\n",
    "# define the evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, count_vectorizer, idf, string_indexer, lr])\n",
    "\n",
    "# define the cross-validator\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# fit pipeline to the training data\n",
    "cv_model = cv.fit(train_data)\n",
    "\n",
    "# make predictions on the test data\n",
    "predictions = cv_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8352\n",
      "F1 score: 0.8076\n",
      "Recall: 0.8352\n",
      "Precision: 0.8069\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "# Calculate recall\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Calculate precision\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"F1 score: {:.4f}\".format(f1_score))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[72.  3.]\n",
      " [12.  4.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# Convert the predictions and labels to an RDD\n",
    "predictionAndLabels = predictions.select(\"prediction\", \"label_index\").rdd.map(lambda r: (r[0], r[1]))\n",
    "\n",
    "# Instantiate a MulticlassMetrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# Get the confusion matrix as a NumPy array\n",
    "confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get the best model from the cross-validation process\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mcv_model\u001b[49m\u001b[38;5;241m.\u001b[39mbestModel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Save the my_model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m best_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_logistic_regression\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the best model from the cross-validation process\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# Save the my_model\n",
    "best_model.save(\"my_logistic_regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "globals()['models_loaded'] = False\n",
    "globals()['my_model'] = None\n",
    "\n",
    "# Toy predict function that returns a random probability. Normally you'd use your loaded globals()['my_model'] here\n",
    "# def predict(df):\n",
    "#     return random.random()\n",
    "\n",
    "# predict_udf = udf(predict, StringType())\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    df = df.withColumn(\"label\", col(\"label\").cast(\"float\"))\n",
    "    df.show()\n",
    "    \n",
    "#     # Utilize our predict function\n",
    "#     df_withpreds = df.withColumn(\"pred\", predict_udf(\n",
    "#         struct([df[x] for x in df.columns])\n",
    "#     ))\n",
    "#     df_withpreds.show()\n",
    "    \n",
    "    # Normally, you wouldn't use a UDF (User Defined Function) Python function to predict as we did here (you can)\n",
    "    # but an MLlib model you've built and saved with Spark\n",
    "    # In this case, you need to prevent loading your model in every call to \"process\" as follows:\n",
    "    \n",
    "    # Load in the model if not yet loaded:\n",
    "    if not globals()['models_loaded']:\n",
    "        # load in your models here\n",
    "        globals()['my_model'] = PipelineModel.load('my_logistic_regression')\n",
    "        globals()['models_loaded'] = True\n",
    "        \n",
    "    # And then predict using the loaded model (uncomment below):\n",
    "    \n",
    "    df_result = globals()['my_model'].transform(df)\n",
    "    df_result.select('label', 'review_text', 'prediction', 'label_index').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2023-05-21 20:16:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2311190|  1.0|138696311|SO EXITED FOR GAR...|\n",
      "|1375900|  1.0|138695647|               great|\n",
      "|1742020|  1.0|138698127|                 The|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|SO EXITED FOR GAR...|       0.0|        0.0|\n",
      "|  1.0|               great|       0.0|        0.0|\n",
      "|  1.0|                 The|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:16:40 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1557990|  1.0|138694719|i swear. i made s...|\n",
      "|1940340|  0.0|138697687|- Restart the run...|\n",
      "|1940340|  1.0|138694794|Morrer na primeir...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|i swear. i made s...|       0.0|        0.0|\n",
      "|  0.0|- Restart the run...|       0.0|        1.0|\n",
      "|  1.0|Morrer na primeir...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:16:50 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2151580|  1.0|138696804|[h1] üïò          ...|\n",
      "| 669330|  1.0|138697670|SC Tavern made in...|\n",
      "| 669330|  1.0|138697019|Simple to pick up...|\n",
      "| 669330|  1.0|138696811|Finally a competi...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|[h1] üïò          ...|       1.0|        0.0|\n",
      "|  1.0|SC Tavern made in...|       0.0|        0.0|\n",
      "|  1.0|Simple to pick up...|       0.0|        0.0|\n",
      "|  1.0|Finally a competi...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:17:10 =========\n",
      "+-------+-----+---------+-----------+\n",
      "| app_id|label|review_id|review_text|\n",
      "+-------+-----+---------+-----------+\n",
      "|2369390|  1.0|138697355|   POG game|\n",
      "+-------+-----+---------+-----------+\n",
      "\n",
      "+-----+-----------+----------+-----------+\n",
      "|label|review_text|prediction|label_index|\n",
      "+-----+-----------+----------+-----------+\n",
      "|  1.0|   POG game|       0.0|        0.0|\n",
      "+-----+-----------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:17:20 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2369390|  1.0|138697077|Its FC, it is wha...|\n",
      "|2369390|  0.0|138696854|Shitty port from ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|Its FC, it is wha...|       0.0|        0.0|\n",
      "|  0.0|Shitty port from ...|       0.0|        1.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:17:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2369390|  1.0|138696673|                 yes|\n",
      "|2369390|  0.0|138696393|The game crashes ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|                 yes|       0.0|        0.0|\n",
      "|  0.0|The game crashes ...|       0.0|        1.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:17:40 =========\n",
      "+-------+-----+---------+--------------+\n",
      "| app_id|label|review_id|   review_text|\n",
      "+-------+-----+---------+--------------+\n",
      "|2369390|  1.0|138695963|        Decent|\n",
      "|2369390|  1.0|138694627|    awesome \\n|\n",
      "|1983710|  1.0|138695945|simple and fun|\n",
      "+-------+-----+---------+--------------+\n",
      "\n",
      "+-----+--------------+----------+-----------+\n",
      "|label|   review_text|prediction|label_index|\n",
      "+-----+--------------+----------+-----------+\n",
      "|  1.0|        Decent|       0.0|        0.0|\n",
      "|  1.0|    awesome \\n|       0.0|        0.0|\n",
      "|  1.0|simple and fun|       0.0|        0.0|\n",
      "+-----+--------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:17:50 =========\n",
      "+------+-----+---------+--------------------+\n",
      "|app_id|label|review_id|         review_text|\n",
      "+------+-----+---------+--------------------+\n",
      "|605740|  0.0|138696652|      Keeps crashing|\n",
      "|824600|  1.0|138698955|LENIN LIVED, LENI...|\n",
      "+------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  0.0|      Keeps crashing|       0.0|        1.0|\n",
      "|  1.0|LENIN LIVED, LENI...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:18:10 =========\n",
      "+------+-----+---------+--------------------+\n",
      "|app_id|label|review_id|         review_text|\n",
      "+------+-----+---------+--------------------+\n",
      "|705040|  1.0|138699126|It's pretty good ...|\n",
      "+------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|It's pretty good ...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:18:20 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|  1.0|138699572| I'm doing my part !|\n",
      "|1268750|  1.0|138699515|The game is prett...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0| I'm doing my part !|       0.0|        0.0|\n",
      "|  1.0|The game is prett...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:18:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|  1.0|138699490|Im doing my part!...|\n",
      "|1268750|  1.0|138699429|To much screen sh...|\n",
      "|1268750|  1.0|138699268|The only good bug...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|Im doing my part!...|       0.0|        0.0|\n",
      "|  1.0|To much screen sh...|       0.0|        0.0|\n",
      "|  1.0|The only good bug...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:18:40 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|  1.0|138698907|  I'm doing my part.|\n",
      "|1268750|  1.0|138698839|      PART I AM DONE|\n",
      "|1268750|  1.0|138698810|Definitely an ear...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|  I'm doing my part.|       0.0|        0.0|\n",
      "|  1.0|      PART I AM DONE|       0.0|        0.0|\n",
      "|  1.0|Definitely an ear...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:18:50 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|  1.0|138698781|runs fine for a v...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|runs fine for a v...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:19:10 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2016280|  1.0|138698281|Well this is rath...|\n",
      "|1934780|  0.0|138699254|3rd person shoote...|\n",
      "|1934780|  1.0|138699202|Good Game! But fo...|\n",
      "|1934780|  0.0|138699092|The game is okay....|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|Well this is rath...|       0.0|        0.0|\n",
      "|  0.0|3rd person shoote...|       0.0|        1.0|\n",
      "|  1.0|Good Game! But fo...|       0.0|        0.0|\n",
      "|  0.0|The game is okay....|       0.0|        1.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:19:20 =========\n",
      "+-------+-----+---------+----------------------------------+\n",
      "| app_id|label|review_id|                       review_text|\n",
      "+-------+-----+---------+----------------------------------+\n",
      "|1934780|  1.0|138698527|              Pretty solid game...|\n",
      "|1934780|  1.0|138697609|Ïû†Ïû¨Ï†ÅÏù∏ ÏöîÏÜåÍ∞Ä Î¨¥Í∂ÅÎ¨¥ÏßÑÌïú Í≤åÏûÑ...|\n",
      "|1934780|  1.0|138696551|              Good game just tr...|\n",
      "+-------+-----+---------+----------------------------------+\n",
      "\n",
      "+-----+----------------------------------+----------+-----------+\n",
      "|label|                       review_text|prediction|label_index|\n",
      "+-----+----------------------------------+----------+-----------+\n",
      "|  1.0|              Pretty solid game...|       0.0|        0.0|\n",
      "|  1.0|Ïû†Ïû¨Ï†ÅÏù∏ ÏöîÏÜåÍ∞Ä Î¨¥Í∂ÅÎ¨¥ÏßÑÌïú Í≤åÏûÑ...|       0.0|        0.0|\n",
      "|  1.0|              Good game just tr...|       0.0|        0.0|\n",
      "+-----+----------------------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:19:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1934780|  0.0|138696447|as expected game ...|\n",
      "|1934780|  1.0|138696373|   This game is epic|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  0.0|as expected game ...|       0.0|        1.0|\n",
      "|  1.0|   This game is epic|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:19:40 =========\n",
      "+-------+-----+---------+-----------------+\n",
      "| app_id|label|review_id|      review_text|\n",
      "+-------+-----+---------+-----------------+\n",
      "|1934780|  0.0|138695990|So much wall hack|\n",
      "+-------+-----+---------+-----------------+\n",
      "\n",
      "+-----+-----------------+----------+-----------+\n",
      "|label|      review_text|prediction|label_index|\n",
      "+-----+-----------------+----------+-----------+\n",
      "|  0.0|So much wall hack|       0.0|        1.0|\n",
      "+-----+-----------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:19:50 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2248760|  1.0|138698831|Verry good game f...|\n",
      "|2248760|  1.0|138697853|This game at this...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|Verry good game f...|       0.0|        0.0|\n",
      "|  1.0|This game at this...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:20:00 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2008100|  1.0|138699489|Overpriced, janky...|\n",
      "|1304930|  1.0|138699717|brilliant game, c...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|Overpriced, janky...|       0.0|        0.0|\n",
      "|  1.0|brilliant game, c...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:20:10 =========\n",
      "+-------+-----+---------+------------------------------+\n",
      "| app_id|label|review_id|                   review_text|\n",
      "+-------+-----+---------+------------------------------+\n",
      "|1304930|  1.0|138699699|            Great horror game!|\n",
      "|1304930|  1.0|138699627|Ë∞¢Ë∞¢ÔºåÊúâË¢´ÂêìÂà∞\\n‰∏ÄËµ∑ÁªÑÈòüÊ¨¢‰πêÂ§ö|\n",
      "|1304930|  0.0|138699582|          I bought this hop...|\n",
      "+-------+-----+---------+------------------------------+\n",
      "\n",
      "+-----+------------------------------+----------+-----------+\n",
      "|label|                   review_text|prediction|label_index|\n",
      "+-----+------------------------------+----------+-----------+\n",
      "|  1.0|            Great horror game!|       0.0|        0.0|\n",
      "|  1.0|Ë∞¢Ë∞¢ÔºåÊúâË¢´ÂêìÂà∞\\n‰∏ÄËµ∑ÁªÑÈòüÊ¨¢‰πêÂ§ö|       0.0|        0.0|\n",
      "|  0.0|          I bought this hop...|       0.0|        1.0|\n",
      "+-----+------------------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:20:20 =========\n",
      "+-------+-----+---------+-----------+\n",
      "| app_id|label|review_id|review_text|\n",
      "+-------+-----+---------+-----------+\n",
      "|1304930|  1.0|138699569|      funny|\n",
      "|1304930|  1.0|138699533|   Amasing!|\n",
      "+-------+-----+---------+-----------+\n",
      "\n",
      "+-----+-----------+----------+-----------+\n",
      "|label|review_text|prediction|label_index|\n",
      "+-----+-----------+----------+-----------+\n",
      "|  1.0|      funny|       0.0|        0.0|\n",
      "|  1.0|   Amasing!|       0.0|        0.0|\n",
      "+-----+-----------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:20:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1304930|  1.0|138699479|got me shitting m...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|got me shitting m...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:21:00 =========\n",
      "+------+-----+---------+--------------------+\n",
      "|app_id|label|review_id|         review_text|\n",
      "+------+-----+---------+--------------------+\n",
      "|754890|  0.0|138699275|This is a rather ...|\n",
      "|754890|  1.0|138698723|Cyan, through and...|\n",
      "|754890|  0.0|138697719|It pains me, espe...|\n",
      "+------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  0.0|This is a rather ...|       1.0|        1.0|\n",
      "|  1.0|Cyan, through and...|       0.0|        0.0|\n",
      "|  0.0|It pains me, espe...|       0.0|        1.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:21:10 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "| 754890|  1.0|138696932|Great! Nice and s...|\n",
      "|1899060|  1.0|138697988|https://steamcomm...|\n",
      "|1451810|  1.0|138697686|Pretty good compa...|\n",
      "|1037940|  1.0|138699339|Not really a revi...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|Great! Nice and s...|       0.0|        0.0|\n",
      "|  1.0|https://steamcomm...|       0.0|        0.0|\n",
      "|  1.0|Pretty good compa...|       0.0|        0.0|\n",
      "|  1.0|Not really a revi...|       1.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:21:20 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1810510|  1.0|138696203|This game has ama...|\n",
      "|2078510|  1.0|138695794|Couple bugs aside...|\n",
      "|1465560|  0.0|138698630|Short Pros/Cons:\\...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|This game has ama...|       0.0|        0.0|\n",
      "|  1.0|Couple bugs aside...|       0.0|        0.0|\n",
      "|  0.0|Short Pros/Cons:\\...|       0.0|        1.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:21:50 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2392070|  1.0|138695819|This casual game ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|This casual game ...|       1.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:22:00 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2287980|  1.0|138696481|[code]Placeholder...|\n",
      "|1694510|  1.0|138698582|Pretty fun. Used ...|\n",
      "|2382730|  1.0|138698384|Noice\\n\\nPros:\\nA...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|[code]Placeholder...|       0.0|        0.0|\n",
      "|  1.0|Pretty fun. Used ...|       0.0|        0.0|\n",
      "|  1.0|Noice\\n\\nPros:\\nA...|       1.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n",
      "========= 2023-05-21 20:15:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2311190|  1.0|138696311|SO EXITED FOR GAR...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|SO EXITED FOR GAR...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
