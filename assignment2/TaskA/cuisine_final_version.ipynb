{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce3d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install reportlab\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a17fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc='/Users/wentingjiang/Downloads/assignment2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c49bf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(loc+'dataset.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0f777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at json\n",
    "# multiple labels per restaurant\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    labels = [d['label'] for d in data[i]['cuisines']]\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract image IDs of one restaurant\n",
    "one_restaurant_info=data[0]['more_details']['full_images']\n",
    "one_restaurant_images=[i['image_id'] for i in one_restaurant_info]\n",
    "one_restaurant_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this for all restaurants\n",
    "import random\n",
    "res_image_dic={}\n",
    "cuisine_dic={}\n",
    "for res in data:\n",
    "    # use cuisine type as restaurant \n",
    "    res_id= res['identifier']\n",
    "    one_restaurant_info=res['more_details']['full_images']\n",
    "    one_restaurant_images=[i['image_id'] for i in one_restaurant_info]\n",
    "    if len(one_restaurant_images)!=0:\n",
    "    # select 1 images per restaurant, otherwise too many images\n",
    "        selected= one_restaurant_images[-1]#random.choices(one_restaurant_images,k=1)\n",
    "    res_image_dic[res_id]=selected\n",
    "    cuisine_dic[res_id] = [d['label'] for d in res['cuisines']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cuisine_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cuisine names\n",
    "flat_list = [item for sublist in cuisine_dic.values() for item in sublist]\n",
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f693e8b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(flat_list)\n",
    "\n",
    "df = pd.DataFrame(list(counter.items()), columns=['Element', 'Count'])\n",
    "\n",
    "# Sort the DataFrame by count in descending order\n",
    "df = df.sort_values(by=['Count'], ascending=False)\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# look at the most frequently appearing types\n",
    "dfs= df.iloc[:30,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b35dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.Element.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sort_values(by='Number of Restaurants', ascending=False)\n",
    "plt.barh(dfs['Element'], dfs['Count'])\n",
    "plt.xlabel('Number of Restaurants')\n",
    "plt.ylabel('Cuisine')\n",
    "plt.title('Number of Restaurants by Cuisine')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_tags= [ #'Modern Cuisine',\n",
    "#  'Traditional Cuisine',\n",
    "#  'Creative',\n",
    "#  'Contemporary',\n",
    "#  'Market Cuisine',\n",
    "#  'Seafood',\n",
    " 'Italian',\n",
    "#  'Classic Cuisine',\n",
    " 'Japanese',\n",
    "#  'Country cooking',\n",
    "#  'Mediterranean Cuisine',\n",
    "#  'International',\n",
    "#  'Regional Cuisine',\n",
    " 'French',\n",
    "  'Modern British',\n",
    "#  'Street Food',\n",
    "#  'Modern French',\n",
    "#  'Seasonal Cuisine',\n",
    "  'Cantonese',\n",
    "#  'American',\n",
    "  'Sushi',\n",
    "#  'Classic French',\n",
    " 'Chinese',\n",
    " 'Thai',\n",
    "#  'Fusion',\n",
    "#  'Italian Contemporary',\n",
    "#  'French Contemporary',\n",
    " 'Indian',\n",
    "#  'Meats and Grills',\n",
    "# 'Mexican'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2877cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# filter restaurant ID that corresponds to the tag above \n",
    "# Filter the keys in the dictionary whose items are in the list\n",
    "filtered_dict = {k: v for k, v in cuisine_dic.items() if any(elem in v for elem in country_tags)}\n",
    "\n",
    "# Convert the filtered dictionary to a DataFrame\n",
    "filtered_restaurant=pd.DataFrame.from_dict(filtered_dict, orient='index')#, columns=['Cuisine'])\n",
    "filtered_restaurant.columns=['tag1','tag2']\n",
    "filtered_restaurant['tag1'] = filtered_restaurant['tag1'].replace('Cantonese', 'Chinese')\n",
    "\n",
    "filtered_restaurant['tag1'] = filtered_restaurant['tag1'].replace('Sushi', 'Japanese')\n",
    "filtered_restaurant['tag1'] = filtered_restaurant['tag1'].replace('Modern French', 'French')\n",
    "\n",
    "# in someg cases, a restaurant has two tags, two similar country cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a34aa8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered_restaurant_single_tag=filtered_restaurant[filtered_restaurant['tag2'].isna()].reset_index()\n",
    "filtered_restaurant_single_tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes are somewhat imbalanced\n",
    "filtered_restaurant_single_tag.groupby('tag1').count()\n",
    "\n",
    "#could just choose the classes that are more balanced: French, Italian, Japense, Modern British\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08bad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_id_selected =list(filtered_restaurant_single_tag['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1792a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = [res_image_dic[k] for k in restaurant_id_selected]\n",
    "#image_names\n",
    "\n",
    "filtered_restaurant_single_tag['image_id']=image_names\n",
    "#filtered_restaurant_single_tag\n",
    "\n",
    "image_id_label=filtered_restaurant_single_tag.set_index('image_id')['tag1'].to_dict()\n",
    "image_id_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e38ac86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test reading an image\n",
    "#folder_path = '/Users/wentingjiang/Downloads/assignment2/images'\n",
    "#image_path=folder_path + '/' + image_names[0] + '.jpg'\n",
    "#img=Image.open(image_path)\n",
    "#img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b195b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reading all images in a restaurant setting  (for relevant cuisines)\n",
    "all_images={}\n",
    "folder_path = '/Users/wentingjiang/Downloads/assignment2/images'\n",
    "#target_size = (256, 256) # need to resize because some images do not have the same shap\n",
    "target_size = (128, 128) # use smaller size to make computation more efficient\n",
    "\n",
    "for name in image_names:\n",
    "    file_name=name + '.jpg'\n",
    "    image_path = folder_path + '/' + file_name\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img = img.resize(target_size)\n",
    "            image_array = np.array(img)\n",
    "            if image_array.shape == (128, 128, 3):\n",
    "                all_images[name]=image_array\n",
    "            #print(name)\n",
    "    except:\n",
    "        print(f\"Error opening file '{file_name}', skipping...\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361acb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(all_images['1955140'], cmap='gray')\n",
    "#plt.show() # quality of 64x64 becomes much worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731aaef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_image_list=[]\n",
    "test_image_names=[]\n",
    "test_labels=[]\n",
    "for i in all_images: \n",
    "    test_image_list.append(all_images[i])\n",
    "    test_image_names.append(i)\n",
    "    test_labels.append(image_id_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db1f5e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=np.array(test_image_list)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deceea4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707709b0",
   "metadata": {},
   "source": [
    "# Filter filter out non-food images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1318fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc='/Users/wentingjiang/Downloads/assignment2/'\n",
    "# path to the folder containing the JSON files\n",
    "folder_path = loc+'labels/'\n",
    "# get a list of all the files in the folder\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "label_dict={}\n",
    "# iterate over the files\n",
    "for file_name in file_list:\n",
    "    # check if the file is a JSON file\n",
    "    if file_name.endswith('.json'):\n",
    "        # construct the full path to the file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # open the file and read its contents\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)        \n",
    "        txt=json_data['imagePath']\n",
    "        image_id=txt.split(\".\")[0]\n",
    "        label_dict[image_id]=int(json_data['flags']['food'])\n",
    "        print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab445a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just use the previous model to predict and see the outcome\n",
    "\n",
    "image_names_test=list(label_dict.keys())\n",
    "image_labels_test=list(label_dict.values())\n",
    "\n",
    "# reading all images in a restaurant setting \n",
    "#all_test_images={}\n",
    "folder_path = loc+'images'\n",
    "target_size = (128, 128) # need to resize because some images do not have the same shap\n",
    "\n",
    "# read all\n",
    "test_label=[]\n",
    "new_test_image_list= []\n",
    "for ind,name in enumerate(image_names_test):\n",
    "    file_name=name + '.jpg'\n",
    "    image_path = folder_path + '/' + file_name\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img = img.resize(target_size)\n",
    "            image_array = np.array(img)\n",
    "            #all_test_images[name]=image_array       \n",
    "            new_test_image_list.append(image_array)\n",
    "            test_label.append(image_labels_test[ind])\n",
    "            #print(name)\n",
    "    except:\n",
    "        print(f\"Error opening file '{file_name}', skipping...\")\n",
    "        continue\n",
    "\n",
    "print('read ' + str(len(new_test_image_list)) + ' images')\n",
    "\n",
    "sum(test_label)/len(test_label)\n",
    "# there is a slight issue of class imbalance, accuracy is not be the best metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0875497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_test=np.array(new_test_image_list)\n",
    "new_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d4ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    new_test, np.array(test_label), test_size=0.2, stratify=np.array(test_label), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49db6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(y_train),\n",
    "                                        y = y_train                                                    \n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(y_train), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594c126",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.applications import VGG16\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze pre-trained layers (compare with no freezing)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "\n",
    "# Define your own classification layers\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73103cea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history=model.fit(X_train, y_train, class_weight=class_weights, \n",
    "                  epochs=10, batch_size=32, validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Evaluate the model on test set\n",
    "#score = model.evaluate(X_test, y_test)\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aabb7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss curve\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32079aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffce9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_test=model.predict(X_test)\n",
    "threshold = 0.99999 # play around this threshold\n",
    "\n",
    "predicted_labels_test = (model_predictions_test > threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted_labels_test)\n",
    "print(accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098740a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a87c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, predicted_labels_test)\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c525cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_label_dict={1: 'food', 0: 'exterior'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a917870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find misclassified images\n",
    "def find_mismatch_pos(list1, list2):\n",
    "    all_pos=[]\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] != list2[i]:\n",
    "            all_pos.append(i)\n",
    "    return all_pos # if no mismatch found\n",
    "\n",
    "misclassified = find_mismatch_pos(y_test, predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab8f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ind, item in enumerate(misclassified):\n",
    "    predict_label=predicted_labels_test[item][0]\n",
    "    actual_label=y_test[item]\n",
    "    print('image ' + str(ind) + ' actual label:' + (convert_label_dict[actual_label]))\n",
    "    print('image ' + str(ind) + ' predict label:' + (convert_label_dict[predict_label]))\n",
    "    plt.imshow(new_test[item], cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "# image 4 has a wrong label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # show images in order to check prediction \n",
    "for ind, item in enumerate(X_test):\n",
    "    label=predicted_labels_test[ind][0]\n",
    "    print('image ' + str(ind) + ' label:' + (convert_label_dict[label]))\n",
    "    plt.imshow(item, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f3e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(filename):\n",
    "    p = PdfPages(filename)\n",
    "    for ind, item in enumerate(new_images): # show images in order to check prediction \n",
    "        label=predicted_labels[ind][0]\n",
    "        fig= plt.figure()\n",
    "        plt.imshow(item, cmap='gray')\n",
    "        plt.title('image ' + str(ind) + ' label:' + (convert_label_dict[label]))\n",
    "        fig.savefig(p, format='pdf') \n",
    "    # close the object\n",
    "    p.close()  \n",
    "    \n",
    "# name Pdf file\n",
    "#filename = \"multi_plot_image2.pdf\"  \n",
    "#save_image(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"food_interior_classifier3.h5\")\n",
    "#somehow not saved properly, cannot load the model later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a138d7",
   "metadata": {},
   "source": [
    "# Load saved food vs exterior model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dacb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ab244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e196a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model = tf.keras.models.load_model('food_interior_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1917d064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict new images with the model\n",
    "model_predictions=model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401fd36b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(model_predictions) # probabilities are at two extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the threshold\n",
    "threshold = 0.5 # adjust this threshold to make sure what we predict as food is really food\n",
    "\n",
    "# convert predicted probabilities to labels 0 and 1\n",
    "predicted_labels = (model_predictions > threshold).astype(int)\n",
    "# print the predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba478d0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d337ae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb98b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict={1: 'food', 0: 'exterior'}\n",
    "predicted=[]\n",
    "\n",
    "food_only=[]\n",
    "cuisine_labels=[]\n",
    "image_name=[]\n",
    "for ind, item in enumerate(test): # show images in order to check prediction \n",
    "    label=predicted_labels[ind][0]\n",
    "    predicted.append(label)\n",
    "    if label==1:\n",
    "        food_only.append(item)\n",
    "        cuisine_labels.append(test_labels[ind])\n",
    "        image_name.append(test_image_names[ind])\n",
    "    #print('image ' + str(ind) + ' label:' + (label_dict[label]))\n",
    "    #plt.imshow(item, cmap='gray')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac680ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf8daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('food_only.txt', 'w') as f:\n",
    "    for item in image_name:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a025f68d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(food_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983d9b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# double check labels\n",
    "#for test_id in range(10):\n",
    "#    plt.imshow(food_only[test_id], cmap='gray')\n",
    "#    plt.title(cuisine_labels[test_id])\n",
    "#    plt.show()\n",
    "\n",
    "round(sum(predicted)/len(predicted),2)\n",
    "# percent predicted as food images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2424707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(filename, food_only):\n",
    "    p = PdfPages(filename)\n",
    "    for ind, item in enumerate(food_only): # show images in order to check prediction \n",
    "        #label=predicted_labels[ind][0]\n",
    "        fig= plt.figure()\n",
    "        plt.imshow(item, cmap='gray')\n",
    "        plt.title('image ' + str(image_name[ind]))\n",
    "        fig.savefig(p, format='pdf') \n",
    "    # close the object\n",
    "    p.close()\n",
    "#filename = \"cuisine_food_predicted2.pdf\"  \n",
    "#save_image(filename, food_only) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7fa951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_image_names, this contains the labels of the test image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aacb8e",
   "metadata": {},
   "source": [
    "# Check about the interior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2405744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrong =['2643058', '778212', '297614', '5414007', '5142831', '2026022', '1250600', '1004760', '2241860', '1198837', '1943514']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = [i for i, x in enumerate(image_name) if x in wrong]\n",
    "# indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a4ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuisine_labels_filtered = [cuisine_labels[i] for i in range(len(cuisine_labels)) if i not in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cc1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# food_only_filtered = [food_only[i] for i in range(len(food_only)) if i not in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d4660c",
   "metadata": {},
   "source": [
    "# Modelling after filtering out non-food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e56228",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c8c39a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_labels= cuisine_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2281823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "  \n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'species'.\n",
    "final_labels_int= label_encoder.fit_transform(final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74dd604",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_cat=pd.DataFrame(final_labels)\n",
    "class_cat.columns=['label']\n",
    "dummies = pd.get_dummies(class_cat)\n",
    "dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51e287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set(final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e5433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_cat.reset_index().groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c35ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(food_only)\n",
    "y= np.array(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c0ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "#https://stackoverflow.com/questions/51951358/keras-how-to-get-top-k-accuracy\n",
    "#top3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "#top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "#original_labels = np.argmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify= final_labels_int, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights2 = compute_class_weight(\n",
    "#                                         class_weight = \"balanced\",\n",
    "#                                         classes = np.unique(final_labels_int),\n",
    "#                                         y = final_labels_int                                                    \n",
    "#                                     )\n",
    "# class_weights2 = dict(zip(np.unique(final_labels_int), class_weights))\n",
    "# class_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.applications import VGG16\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Load the pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze pre-trained layers (compare with no freezing)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "    \n",
    "# Define your own classification layers\n",
    "model_cusine = Sequential()\n",
    "model_cusine.add(base_model)\n",
    "model_cusine.add(Dropout(0.2)) # avoid overfitting\n",
    "model_cusine.add(Flatten())\n",
    "\n",
    "\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "\n",
    "#val acc>0.2\n",
    "model_cusine.add(Dense(64, activation='relu'))\n",
    "#model.add(Dropout(0.2)) # adding it twuice to avoid overfitting\n",
    "model_cusine.add(Dense(64, activation='relu'))\n",
    "#model.add(Dropout(0.2)) # adding it twuice to avoid overfitting\n",
    "\n",
    "model_cusine.add(Dense(7, activation='softmax'))\n",
    "#https://datascience.stackexchange.com/questions/39264/how-does-sigmoid-activation-work-in-multi-class-classification-problems\n",
    "\n",
    "# Compile the model\n",
    "model_cusine.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','top_k_categorical_accuracy'])\n",
    "              #,top3_acc]) #sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c0bc7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_cusine.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels_y_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "\n",
    "# from sklearn.utils import class_weight\n",
    "# class_weights = compute_class_weight(class_weight = \"balanced\",\n",
    "#                                          classes = np.unique(original_labels_y_train),\n",
    "#                                          y = original_labels_y_train                                                    \n",
    "#                                      )\n",
    "# class_weights = dict(zip(np.unique(original_labels_y_train), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f665e3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329443c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history2=model_cusine.fit(X_train, y_train, #class_weight=class_weights, \n",
    "                          epochs=10, batch_size=16, \n",
    "                          validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Evaluate the model on test set\n",
    "#score = model_cusine.evaluate(X_test, y_test)\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b6e82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot loss curve\n",
    "plt.plot(history2.history['loss'], label='training loss')\n",
    "plt.plot(history2.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece5c3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_prob = model_cusine.predict(X)\n",
    "y_pred = [int(np.argmax(i) )for i in y_pred_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03031a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#y_pred_prob = model_cusine.predict(X_test)\n",
    "#y_pred = [int(np.argmax(i) )for i in y_pred_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37615379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_labels = np.argmax(y, axis=1)\n",
    "original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fed87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f206c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Define your actual class names as a list\n",
    "class_names = ['Chinese',\n",
    " 'French',\n",
    " 'Indian',\n",
    " 'Italian',\n",
    " 'Japanese',\n",
    " 'Modern British',\n",
    " 'Thai']\n",
    "\n",
    "# Generate some example data for demonstration purposes\n",
    "# Including both training and test\n",
    "y_pred = y_pred\n",
    "y_true = original_labels\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00fda8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define a function to plot the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87504f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually go through the food images, anyone exterior image there? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now either consider class weight, or make them more balanced manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ad93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different losses, sparse_categorical vs categorical, try using y as label encoded vs dummy encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some misclassified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90bf915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add explanation technique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
