{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.171:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.171:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1be77236320>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2088, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(\"reviews.csv\", sep=',')\n",
    "df = df[['review_id', 'app_id', 'review_text', 'label']]\n",
    "df.to_csv('reviews.csv', sep='\\t', index=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_id  app_id  review_text\n",
       "label                                \n",
       "0.0           71      71           71\n",
       "1.0          394     394          394"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8473118279569892"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer, HashingTF\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "file_location=\"reviews.csv\"\n",
    "#text_df = spark.read.text(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"assignment 3\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.cores\", \"2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         review_text|label|\n",
      "+--------------------+-----+\n",
      "|i can confirm tha...|  1.0|\n",
      "|Really good game,...|  1.0|\n",
      "|Its not finished ...|  1.0|\n",
      "|Hey. It's really ...|  1.0|\n",
      "|          Fun so far|  1.0|\n",
      "|I'd rather play W...|  0.0|\n",
      "|I have been playi...|  1.0|\n",
      "|Nice game!\\nLoads...|  1.0|\n",
      "|All hail NA serve...|  1.0|\n",
      "|enjoying it so fa...|  1.0|\n",
      "|This game came as...|  1.0|\n",
      "|        Great fun \\n|  1.0|\n",
      "|Fantastic consept...|  1.0|\n",
      "|You know the game...|  1.0|\n",
      "|EDIT: My issues h...|  1.0|\n",
      "|AMAZIIIIIIIIIIING...|  1.0|\n",
      "|In its current st...|  0.0|\n",
      "|Играю в Калибр го...|  1.0|\n",
      "|Secret Word: Prou...|  1.0|\n",
      "|Fated Word: Death...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#text_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\", \"true\").csv(file_location)\n",
    "\n",
    "# read csv\n",
    "\n",
    "text_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .csv(file_location)\n",
    "\n",
    "text_df = text_df.select(col('review_text'), col('label'))\n",
    "text_df = text_df.dropna()\n",
    "text_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: (433, 2)\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows and columns in the DataFrame\n",
    "num_rows = text_df.count()\n",
    "num_cols = len(text_df.columns)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(\"Shape of the DataFrame: (%d, %d)\" % (num_rows, num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "text_df = text_df.dropDuplicates()\n",
    "# Remove rows with missing values\n",
    "text_df = text_df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|  0.0|\n",
      "|  1.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_df.select(\"label\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering:  433\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with unexpected labels\n",
    "text_df = text_df.filter((col(\"label\") == 1.0) | (col(\"label\") == 0.0))\n",
    "print(\"Number of rows after filtering: \", text_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         review_text|label|\n",
      "+--------------------+-----+\n",
      "| Similar to Battl...|  1.0|\n",
      "|\"(BTW I have a bi...|  0.0|\n",
      "|\"Could be an inte...|  1.0|\n",
      "|\"Fun action rogue...|  1.0|\n",
      "|\"I buy a few new ...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = text_df.limit(10000).randomSplit([0.8, 0.2], seed=7)\n",
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "tokenizer = Tokenizer(inputCol=\"review_text\", outputCol=\"words\")\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\", locale=\"en_US\")\n",
    "count_vectorizer = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"raw_features\")\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "string_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
    "\n",
    "# create model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define params grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "   .addGrid(count_vectorizer.vocabSize, [1000, 5000]) \\\n",
    "   .addGrid(lr.regParam, [0.01, 0.1]) \\\n",
    "   .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "   .build()\n",
    "\n",
    "# define the evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, count_vectorizer, idf, string_indexer, lr])\n",
    "\n",
    "# define the cross-validator\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# fit pipeline to the training data\n",
    "cv_model = cv.fit(train_data)\n",
    "\n",
    "# make predictions on the test data\n",
    "predictions = cv_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8352\n",
      "F1 score: 0.8076\n",
      "Recall: 0.8352\n",
      "Precision: 0.8069\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "# Calculate recall\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Calculate precision\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"F1 score: {:.4f}\".format(f1_score))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[72.  3.]\n",
      " [12.  4.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# Convert the predictions and labels to an RDD\n",
    "predictionAndLabels = predictions.select(\"prediction\", \"label_index\").rdd.map(lambda r: (r[0], r[1]))\n",
    "\n",
    "# Instantiate a MulticlassMetrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# Get the confusion matrix as a NumPy array\n",
    "confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get the best model from the cross-validation process\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mcv_model\u001b[49m\u001b[38;5;241m.\u001b[39mbestModel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Save the my_model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m best_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_logistic_regression\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the best model from the cross-validation process\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# Save the my_model\n",
    "best_model.save(\"my_logistic_regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "globals()['models_loaded'] = False\n",
    "globals()['my_model'] = None\n",
    "\n",
    "# Toy predict function that returns a random probability. Normally you'd use your loaded globals()['my_model'] here\n",
    "# def predict(df):\n",
    "#     return random.random()\n",
    "\n",
    "# predict_udf = udf(predict, StringType())\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    df = df.withColumn(\"label\", col(\"label\").cast(\"float\"))\n",
    "    df.show()\n",
    "    \n",
    "#     # Utilize our predict function\n",
    "#     df_withpreds = df.withColumn(\"pred\", predict_udf(\n",
    "#         struct([df[x] for x in df.columns])\n",
    "#     ))\n",
    "#     df_withpreds.show()\n",
    "    \n",
    "    # Normally, you wouldn't use a UDF (User Defined Function) Python function to predict as we did here (you can)\n",
    "    # but an MLlib model you've built and saved with Spark\n",
    "    # In this case, you need to prevent loading your model in every call to \"process\" as follows:\n",
    "    \n",
    "    # Load in the model if not yet loaded:\n",
    "    if not globals()['models_loaded']:\n",
    "        # load in your models here\n",
    "        globals()['my_model'] = PipelineModel.load('my_logistic_regression')\n",
    "        globals()['models_loaded'] = True\n",
    "        \n",
    "    # And then predict using the loaded model (uncomment below):\n",
    "    \n",
    "    df_result = globals()['my_model'].transform(df)\n",
    "    df_result.select('label', 'review_text', 'prediction', 'label_index').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2023-05-21 20:16:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2311190|  1.0|138696311|SO EXITED FOR GAR...|\n",
      "|1375900|  1.0|138695647|               great|\n",
      "|1742020|  1.0|138698127|                 The|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|SO EXITED FOR GAR...|       0.0|        0.0|\n",
      "|  1.0|               great|       0.0|        0.0|\n",
      "|  1.0|                 The|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:16:40 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1557990|  1.0|138694719|i swear. i made s...|\n",
      "|1940340|  0.0|138697687|- Restart the run...|\n",
      "|1940340|  1.0|138694794|Morrer na primeir...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|i swear. i made s...|       0.0|        0.0|\n",
      "|  0.0|- Restart the run...|       0.0|        1.0|\n",
      "|  1.0|Morrer na primeir...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:16:50 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2151580|  1.0|138696804|[h1] 🕘          ...|\n",
      "| 669330|  1.0|138697670|SC Tavern made in...|\n",
      "| 669330|  1.0|138697019|Simple to pick up...|\n",
      "| 669330|  1.0|138696811|Finally a competi...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|[h1] 🕘          ...|       1.0|        0.0|\n",
      "|  1.0|SC Tavern made in...|       0.0|        0.0|\n",
      "|  1.0|Simple to pick up...|       0.0|        0.0|\n",
      "|  1.0|Finally a competi...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:17:10 =========\n",
      "+-------+-----+---------+-----------+\n",
      "| app_id|label|review_id|review_text|\n",
      "+-------+-----+---------+-----------+\n",
      "|2369390|  1.0|138697355|   POG game|\n",
      "+-------+-----+---------+-----------+\n",
      "\n",
      "+-----+-----------+----------+-----------+\n",
      "|label|review_text|prediction|label_index|\n",
      "+-----+-----------+----------+-----------+\n",
      "|  1.0|   POG game|       0.0|        0.0|\n",
      "+-----+-----------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:17:20 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2369390|  1.0|138697077|Its FC, it is wha...|\n",
      "|2369390|  0.0|138696854|Shitty port from ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|Its FC, it is wha...|       0.0|        0.0|\n",
      "|  0.0|Shitty port from ...|       0.0|        1.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:17:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2369390|  1.0|138696673|                 yes|\n",
      "|2369390|  0.0|138696393|The game crashes ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|                 yes|       0.0|        0.0|\n",
      "|  0.0|The game crashes ...|       0.0|        1.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:17:40 =========\n",
      "+-------+-----+---------+--------------+\n",
      "| app_id|label|review_id|   review_text|\n",
      "+-------+-----+---------+--------------+\n",
      "|2369390|  1.0|138695963|        Decent|\n",
      "|2369390|  1.0|138694627|    awesome \\n|\n",
      "|1983710|  1.0|138695945|simple and fun|\n",
      "+-------+-----+---------+--------------+\n",
      "\n",
      "+-----+--------------+----------+-----------+\n",
      "|label|   review_text|prediction|label_index|\n",
      "+-----+--------------+----------+-----------+\n",
      "|  1.0|        Decent|       0.0|        0.0|\n",
      "|  1.0|    awesome \\n|       0.0|        0.0|\n",
      "|  1.0|simple and fun|       0.0|        0.0|\n",
      "+-----+--------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:17:50 =========\n",
      "+------+-----+---------+--------------------+\n",
      "|app_id|label|review_id|         review_text|\n",
      "+------+-----+---------+--------------------+\n",
      "|605740|  0.0|138696652|      Keeps crashing|\n",
      "|824600|  1.0|138698955|LENIN LIVED, LENI...|\n",
      "+------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  0.0|      Keeps crashing|       0.0|        1.0|\n",
      "|  1.0|LENIN LIVED, LENI...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:18:10 =========\n",
      "+------+-----+---------+--------------------+\n",
      "|app_id|label|review_id|         review_text|\n",
      "+------+-----+---------+--------------------+\n",
      "|705040|  1.0|138699126|It's pretty good ...|\n",
      "+------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|It's pretty good ...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:18:20 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|  1.0|138699572| I'm doing my part !|\n",
      "|1268750|  1.0|138699515|The game is prett...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0| I'm doing my part !|       0.0|        0.0|\n",
      "|  1.0|The game is prett...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:18:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|  1.0|138699490|Im doing my part!...|\n",
      "|1268750|  1.0|138699429|To much screen sh...|\n",
      "|1268750|  1.0|138699268|The only good bug...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|Im doing my part!...|       0.0|        0.0|\n",
      "|  1.0|To much screen sh...|       0.0|        0.0|\n",
      "|  1.0|The only good bug...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:18:40 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|  1.0|138698907|  I'm doing my part.|\n",
      "|1268750|  1.0|138698839|      PART I AM DONE|\n",
      "|1268750|  1.0|138698810|Definitely an ear...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|  I'm doing my part.|       0.0|        0.0|\n",
      "|  1.0|      PART I AM DONE|       0.0|        0.0|\n",
      "|  1.0|Definitely an ear...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:18:50 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|  1.0|138698781|runs fine for a v...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|runs fine for a v...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:19:10 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2016280|  1.0|138698281|Well this is rath...|\n",
      "|1934780|  0.0|138699254|3rd person shoote...|\n",
      "|1934780|  1.0|138699202|Good Game! But fo...|\n",
      "|1934780|  0.0|138699092|The game is okay....|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|Well this is rath...|       0.0|        0.0|\n",
      "|  0.0|3rd person shoote...|       0.0|        1.0|\n",
      "|  1.0|Good Game! But fo...|       0.0|        0.0|\n",
      "|  0.0|The game is okay....|       0.0|        1.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:19:20 =========\n",
      "+-------+-----+---------+----------------------------------+\n",
      "| app_id|label|review_id|                       review_text|\n",
      "+-------+-----+---------+----------------------------------+\n",
      "|1934780|  1.0|138698527|              Pretty solid game...|\n",
      "|1934780|  1.0|138697609|잠재적인 요소가 무궁무진한 게임...|\n",
      "|1934780|  1.0|138696551|              Good game just tr...|\n",
      "+-------+-----+---------+----------------------------------+\n",
      "\n",
      "+-----+----------------------------------+----------+-----------+\n",
      "|label|                       review_text|prediction|label_index|\n",
      "+-----+----------------------------------+----------+-----------+\n",
      "|  1.0|              Pretty solid game...|       0.0|        0.0|\n",
      "|  1.0|잠재적인 요소가 무궁무진한 게임...|       0.0|        0.0|\n",
      "|  1.0|              Good game just tr...|       0.0|        0.0|\n",
      "+-----+----------------------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:19:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1934780|  0.0|138696447|as expected game ...|\n",
      "|1934780|  1.0|138696373|   This game is epic|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  0.0|as expected game ...|       0.0|        1.0|\n",
      "|  1.0|   This game is epic|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:19:40 =========\n",
      "+-------+-----+---------+-----------------+\n",
      "| app_id|label|review_id|      review_text|\n",
      "+-------+-----+---------+-----------------+\n",
      "|1934780|  0.0|138695990|So much wall hack|\n",
      "+-------+-----+---------+-----------------+\n",
      "\n",
      "+-----+-----------------+----------+-----------+\n",
      "|label|      review_text|prediction|label_index|\n",
      "+-----+-----------------+----------+-----------+\n",
      "|  0.0|So much wall hack|       0.0|        1.0|\n",
      "+-----+-----------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:19:50 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2248760|  1.0|138698831|Verry good game f...|\n",
      "|2248760|  1.0|138697853|This game at this...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|Verry good game f...|       0.0|        0.0|\n",
      "|  1.0|This game at this...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:20:00 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2008100|  1.0|138699489|Overpriced, janky...|\n",
      "|1304930|  1.0|138699717|brilliant game, c...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|Overpriced, janky...|       0.0|        0.0|\n",
      "|  1.0|brilliant game, c...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:20:10 =========\n",
      "+-------+-----+---------+------------------------------+\n",
      "| app_id|label|review_id|                   review_text|\n",
      "+-------+-----+---------+------------------------------+\n",
      "|1304930|  1.0|138699699|            Great horror game!|\n",
      "|1304930|  1.0|138699627|谢谢，有被吓到\\n一起组队欢乐多|\n",
      "|1304930|  0.0|138699582|          I bought this hop...|\n",
      "+-------+-----+---------+------------------------------+\n",
      "\n",
      "+-----+------------------------------+----------+-----------+\n",
      "|label|                   review_text|prediction|label_index|\n",
      "+-----+------------------------------+----------+-----------+\n",
      "|  1.0|            Great horror game!|       0.0|        0.0|\n",
      "|  1.0|谢谢，有被吓到\\n一起组队欢乐多|       0.0|        0.0|\n",
      "|  0.0|          I bought this hop...|       0.0|        1.0|\n",
      "+-----+------------------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:20:20 =========\n",
      "+-------+-----+---------+-----------+\n",
      "| app_id|label|review_id|review_text|\n",
      "+-------+-----+---------+-----------+\n",
      "|1304930|  1.0|138699569|      funny|\n",
      "|1304930|  1.0|138699533|   Amasing!|\n",
      "+-------+-----+---------+-----------+\n",
      "\n",
      "+-----+-----------+----------+-----------+\n",
      "|label|review_text|prediction|label_index|\n",
      "+-----+-----------+----------+-----------+\n",
      "|  1.0|      funny|       0.0|        0.0|\n",
      "|  1.0|   Amasing!|       0.0|        0.0|\n",
      "+-----+-----------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:20:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1304930|  1.0|138699479|got me shitting m...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|got me shitting m...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:21:00 =========\n",
      "+------+-----+---------+--------------------+\n",
      "|app_id|label|review_id|         review_text|\n",
      "+------+-----+---------+--------------------+\n",
      "|754890|  0.0|138699275|This is a rather ...|\n",
      "|754890|  1.0|138698723|Cyan, through and...|\n",
      "|754890|  0.0|138697719|It pains me, espe...|\n",
      "+------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  0.0|This is a rather ...|       1.0|        1.0|\n",
      "|  1.0|Cyan, through and...|       0.0|        0.0|\n",
      "|  0.0|It pains me, espe...|       0.0|        1.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:21:10 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "| 754890|  1.0|138696932|Great! Nice and s...|\n",
      "|1899060|  1.0|138697988|https://steamcomm...|\n",
      "|1451810|  1.0|138697686|Pretty good compa...|\n",
      "|1037940|  1.0|138699339|Not really a revi...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|Great! Nice and s...|       0.0|        0.0|\n",
      "|  1.0|https://steamcomm...|       0.0|        0.0|\n",
      "|  1.0|Pretty good compa...|       0.0|        0.0|\n",
      "|  1.0|Not really a revi...|       1.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:21:20 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1810510|  1.0|138696203|This game has ama...|\n",
      "|2078510|  1.0|138695794|Couple bugs aside...|\n",
      "|1465560|  0.0|138698630|Short Pros/Cons:\\...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|This game has ama...|       0.0|        0.0|\n",
      "|  1.0|Couple bugs aside...|       0.0|        0.0|\n",
      "|  0.0|Short Pros/Cons:\\...|       0.0|        1.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:21:50 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2392070|  1.0|138695819|This casual game ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|This casual game ...|       1.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n",
      "========= 2023-05-21 20:22:00 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2287980|  1.0|138696481|[code]Placeholder...|\n",
      "|1694510|  1.0|138698582|Pretty fun. Used ...|\n",
      "|2382730|  1.0|138698384|Noice\\n\\nPros:\\nA...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|[code]Placeholder...|       0.0|        0.0|\n",
      "|  1.0|Pretty fun. Used ...|       0.0|        0.0|\n",
      "|  1.0|Noice\\n\\nPros:\\nA...|       1.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n",
      "========= 2023-05-21 20:15:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2311190|  1.0|138696311|SO EXITED FOR GAR...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-----+--------------------+----------+-----------+\n",
      "|label|         review_text|prediction|label_index|\n",
      "+-----+--------------------+----------+-----------+\n",
      "|  1.0|SO EXITED FOR GAR...|       0.0|        0.0|\n",
      "+-----+--------------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
